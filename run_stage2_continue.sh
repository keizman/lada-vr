#!/bin/bash

# ============================================================
# â–¶ï¸  Stage2 ç»§ç»­è®­ç»ƒè„šæœ¬
# ============================================================
# ç”¨é€”ï¼šä»æœ€æ–°çš„ Stage2 checkpoint ç»§ç»­è®­ç»ƒ
# ä½¿ç”¨ï¼šbash run_stage2_continue.sh
# ============================================================

set -e

export CUDA_VISIBLE_DEVICES=0,1
CONFIG_FILE="configs/basicvsrpp/mosaic_restoration_generic_stage2.py"
WORK_DIR="./experiments/basicvsrpp/mosaic_restoration_generic_stage2"

echo "=========================================="
echo "  Stage2 ç»§ç»­è®­ç»ƒ"
echo "=========================================="
echo ""

# æŸ¥æ‰¾æœ€æ–°çš„checkpoint
LATEST_CKPT=$(ls -t $WORK_DIR/iter_*.pth 2>/dev/null | head -1)

if [ -n "$LATEST_CKPT" ]; then
    echo "âœ… æ‰¾åˆ°checkpoint: $LATEST_CKPT"
    
    # æå–iterationæ•°å­—
    ITER=$(basename "$LATEST_CKPT" | grep -oP 'iter_\K[0-9]+')
    echo "   ä¸Šæ¬¡è®­ç»ƒåˆ°: iteration $ITER"
    echo "   å°†ç»§ç»­è®­ç»ƒ"
    echo ""
    
    # ä¸´æ—¶ç¦ç”¨auto-resume
    if [ -f "$WORK_DIR/last_checkpoint" ]; then
        mv "$WORK_DIR/last_checkpoint" "$WORK_DIR/last_checkpoint.bak"
    fi
    
    echo "ğŸš€ å¯åŠ¨è®­ç»ƒ..."
    echo ""
    
    python -m torch.distributed.launch \
        --nproc_per_node=2 \
        --master_port=29501 \
        scripts/training/train-mosaic-restoration-basicvsrpp.py \
        $CONFIG_FILE \
        --launcher pytorch \
        --load-from "$LATEST_CKPT"
    
    # æ¢å¤last_checkpoint
    if [ -f "$WORK_DIR/last_checkpoint.bak" ]; then
        mv "$WORK_DIR/last_checkpoint.bak" "$WORK_DIR/last_checkpoint"
    fi
else
    echo "ğŸ†• æœªæ‰¾åˆ° Stage2 checkpoint"
    echo "   è¯·å…ˆè¿è¡Œ: bash run_stage2_from_stage1.sh"
    exit 1
fi

echo ""
echo "=========================================="
echo "âœ… è®­ç»ƒå®Œæˆï¼"
echo "=========================================="

