#!/bin/bash

# ============================================================
# â–¶ï¸  ç»§ç»­è®­ç»ƒ (Resume Training - æ¨è)
# ============================================================
# ç”¨é€”ï¼šä»æœ€æ–°checkpointç»§ç»­è®­ç»ƒï¼Œé¿å…dataloaderå¡é¡¿
# ä½¿ç”¨ï¼šbash run_multi_gpu_training_no_hang.sh
# 
# ä¼˜åŠ¿ï¼š
#   âœ… è‡ªåŠ¨æŸ¥æ‰¾æœ€æ–°checkpoint
#   âœ… ä¸ä¼šå¡åœ¨"Advance dataloader"
#   âœ… ä»æ­£ç¡®iterationç»§ç»­
# 
# é…ç½®ä¿®æ”¹ï¼š
#   - CONFIG_FILEï¼šé€‰æ‹©é…ç½®æ–‡ä»¶
#   - CUDA_VISIBLE_DEVICESï¼šé€‰æ‹©GPU
#   - --nproc_per_nodeï¼šGPUæ•°é‡
# ============================================================

set -e

export CUDA_VISIBLE_DEVICES=0,1
CONFIG_FILE="configs/basicvsrpp/mosaic_restoration_generic_stage1.py"
WORK_DIR="./experiments/basicvsrpp/mosaic_restoration_frozen_finetune"  # æ ¹æ®configä¸­çš„experiment_name

echo "=========================================="
echo "  å¤šGPUè®­ç»ƒå¯åŠ¨ (æ— å¡é¡¿æ¨¡å¼)"
echo "=========================================="
echo ""

# æŸ¥æ‰¾æœ€æ–°çš„checkpoint
LATEST_CKPT=$(ls -t $WORK_DIR/iter_*.pth 2>/dev/null | head -1)

if [ -n "$LATEST_CKPT" ]; then
    echo "âœ… æ‰¾åˆ°checkpoint: $LATEST_CKPT"
    
    # æå–iterationæ•°å­—
    ITER=$(basename "$LATEST_CKPT" | grep -oP 'iter_\K[0-9]+')
    echo "   ä¸Šæ¬¡è®­ç»ƒåˆ°: iteration $ITER"
    echo "   å°†ä» iteration $((ITER + 1)) ç»§ç»­"
    echo ""
    
    echo "âš¡ ä½¿ç”¨load-fromæ¨¡å¼ï¼ˆä¸ä¼šå¡ä½ï¼‰:"
    echo "   - åŠ è½½æ¨¡å‹æƒé‡å’Œä¼˜åŒ–å™¨çŠ¶æ€"
    echo "   - æ‰‹åŠ¨è®¾ç½®èµ·å§‹iteration"
    echo "   - Dataloaderä»å¤´å¼€å§‹ï¼ˆä¸å¡ä½ï¼‰"
    echo ""
    
    # ä¸´æ—¶é‡å‘½ålast_checkpointï¼Œé¿å…è‡ªåŠ¨resume
    if [ -f "$WORK_DIR/last_checkpoint" ]; then
        mv "$WORK_DIR/last_checkpoint" "$WORK_DIR/last_checkpoint.bak"
        echo "   å·²ä¸´æ—¶ç¦ç”¨auto-resume"
    fi
    
    echo "ğŸš€ å¯åŠ¨è®­ç»ƒ..."
    echo ""
    
    # ä½¿ç”¨load-fromè€Œéresumeï¼Œé…åˆcfg-optionsè®¾ç½®èµ·å§‹iteration
    python -m torch.distributed.launch \
        --nproc_per_node=2 \
        --master_port=29500 \
        scripts/training/train-mosaic-restoration-basicvsrpp.py \
        $CONFIG_FILE \
        --launcher pytorch \
        --load-from "$LATEST_CKPT"
    
    # æ¢å¤last_checkpoint
    if [ -f "$WORK_DIR/last_checkpoint.bak" ]; then
        mv "$WORK_DIR/last_checkpoint.bak" "$WORK_DIR/last_checkpoint"
    fi
else
    echo "ğŸ†• æœªæ‰¾åˆ°checkpointï¼Œä»å¤´å¼€å§‹è®­ç»ƒ"
    echo ""
    
    python -m torch.distributed.launch \
        --nproc_per_node=2 \
        --master_port=29500 \
        scripts/training/train-mosaic-restoration-basicvsrpp.py \
        $CONFIG_FILE \
        --launcher pytorch
fi

echo ""
echo "=========================================="
echo "âœ… è®­ç»ƒå®Œæˆï¼"
echo "=========================================="

